{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5IrF7Rnb_8Fp"},"outputs":[],"source":["!pip install swig --quiet\n","# !pip install gymnasium --quiet\n","!pip install stable_baselines3 --quiet\n","!pip install gymnasium[box2d] --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1710823049562,"user":{"displayName":"Dima Demler","userId":"13194373150138005792"},"user_tz":420},"id":"i54tG3FCACyU","outputId":"4e47e0d9-a2cd-400f-c092-4e283e32358f"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1RCyQOI1i_gXpHt3VOJnq2dG0-KSqMU10/251b_final_project/Dima_colabs/Custom_reward\n"]}],"source":["%cd '/content/drive/MyDrive/CSE_251b/251b_final_project/Dima_colabs/Custom_reward/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xP1M1D5BAXZW"},"outputs":[],"source":["import gymnasium as gym\n","from gymnasium.envs.registration import register\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.monitor import Monitor\n","\n","import os\n","import sys\n","sys.path.append('/content/drive/MyDrive/CSE_251b/251b_final_project/Dima_colabs/Custom_reward/')\n","\n","\n","save_dir = '/content/drive/MyDrive/CSE_251b/251b_final_project/Dima_colabs/Custom_reward/'\n","# model_dir = os.path.join(save_dir, 'car_racing_ppo3')\n","# curr_model_dir = os.path.join(save_dir, 'car_racing_ppo_curr')\n","save_folder = os.path.join(save_dir, 'car_saves')\n","os.makedirs(save_folder, exist_ok=True)\n","best_model_dir = os.path.join(save_folder, 'best_model.zip')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1710823064225,"user":{"displayName":"Dima Demler","userId":"13194373150138005792"},"user_tz":420},"id":"W1K2PWNEA581","outputId":"d44cf9a8-afc3-471f-cad5-45fdc51a5592"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["register(\n","    id='CustomCarRacing-v0',  # Use a new ID for your custom environment\n","    # entry_point='custom2_car_racing:CustomCarRacing',  # Update with the path to your custom class\n","    entry_point='race_car_wrapper:CustomCarRacing',  # Update with the path to your custom class\n","    max_episode_steps=1000,\n","    reward_threshold=900,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"A1mdcQU5AmyP","outputId":"82d3d6d5-28b6-43eb-f36f-fffc1ee71982"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration: 1, Mean reward: -98.9124482, Std reward: 11.019743357514184\n","Model saved at iteration 1\n","Iteration: 2, Mean reward: -150.1621821, Std reward: 4.524551846356416\n","Iteration: 3, Mean reward: -100.43087319999998, Std reward: 32.18019207789487\n","Iteration: 4, Mean reward: -44.700483500000004, Std reward: 29.74239315804118\n","Model saved at iteration 4\n","Iteration: 5, Mean reward: -52.67680399999999, Std reward: 62.194677058475314\n","Iteration: 6, Mean reward: -64.8968366, Std reward: 39.73637890612607\n","Iteration: 7, Mean reward: 229.26974660000005, Std reward: 156.91801511068365\n","Model saved at iteration 7\n","Iteration: 8, Mean reward: 111.92193490000002, Std reward: 126.65402605748946\n","Iteration: 9, Mean reward: -56.1026342, Std reward: 64.48706378125999\n","Iteration: 10, Mean reward: -25.7503238, Std reward: 87.15500246784329\n","Iteration: 11, Mean reward: -9.580738499999999, Std reward: 88.940890718969\n","Iteration: 12, Mean reward: 14.089575400000005, Std reward: 96.95449629984337\n","Iteration: 13, Mean reward: -4.267310499999996, Std reward: 88.42404965877344\n","Iteration: 14, Mean reward: 188.2120418, Std reward: 192.488481451847\n","Iteration: 15, Mean reward: 165.14339740000003, Std reward: 110.10863350905073\n","Iteration: 16, Mean reward: 318.2441835, Std reward: 206.1447710305487\n","Model saved at iteration 16\n","Iteration: 17, Mean reward: 312.9582775, Std reward: 159.81098851412497\n","Iteration: 18, Mean reward: 539.4305835000001, Std reward: 251.20062636460366\n","Model saved at iteration 18\n","Iteration: 19, Mean reward: 776.5560348000001, Std reward: 160.7313878885016\n","Model saved at iteration 19\n","Iteration: 20, Mean reward: 575.1024607, Std reward: 197.4933663578938\n","Iteration: 21, Mean reward: 745.2596314, Std reward: 88.68427126876448\n","Iteration: 22, Mean reward: 761.3212942, Std reward: 142.39490622761284\n","Iteration: 23, Mean reward: 614.3577868, Std reward: 358.32088501866764\n","Iteration: 24, Mean reward: 502.6674422, Std reward: 329.2118894289757\n","Iteration: 25, Mean reward: 216.21173549999997, Std reward: 164.7461835751153\n"]}],"source":["# Create and wrap the environment\n","env = gym.make('CustomCarRacing-v0')\n","env = Monitor(env)  # Wrap the environment with the Monitor wrapper\n","env = DummyVecEnv([lambda: env])  # Then wrap it in a dummy vectorized environment\n","\n","# Initialize the agent\n","model = PPO(\"CnnPolicy\", env, verbose=0)\n","\n","total_iterations = 50\n","time_steps = 5000\n","best_mean_reward = -float('inf')\n","\n","for iteration in range(total_iterations):\n","    model_dir = os.path.join(save_folder, f'model_{iteration + 1}')\n","    # curr_model_dir = os.path.join(save_folder, f'model_{iteration + 1}_curr')\n","    # print(f\"Training epoch: {iteration + 1}/{total_iterations}\")\n","    model.learn(total_timesteps=time_steps, reset_num_timesteps=False)\n","\n","    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n","    print(f\"Iteration: {iteration + 1}, Mean reward: {mean_reward}, Std reward: {std_reward}\")\n","\n","    # Save the current model\n","    model.save(model_dir)\n","    if mean_reward > best_mean_reward:\n","        best_mean_reward = mean_reward\n","        model.save(best_model_dir)\n","        print(f\"Model saved at iteration {iteration + 1}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}